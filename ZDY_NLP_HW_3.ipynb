{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be5fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk import tokenize as tknz\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a4dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(path_or_buf='gazeta_train.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b6d2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.gazeta.ru/financial/2011/11/30/385...</td>\n",
       "      <td>«По итогам 2011 года чистый отток может состав...</td>\n",
       "      <td>Прогноз не успевает за оттоком</td>\n",
       "      <td>В 2011 году из России уйдет $80 млрд, считают ...</td>\n",
       "      <td>2011-11-30 18:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.gazeta.ru/business/2013/01/24/4939...</td>\n",
       "      <td>Российское подразделение интернет-корпорации G...</td>\n",
       "      <td>Google закончил поиск</td>\n",
       "      <td>Юлия Соловьева, экс-директор холдинга «Профмед...</td>\n",
       "      <td>2013-01-24 18:20:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.gazeta.ru/social/2018/02/06/116393...</td>\n",
       "      <td>Басманный районный суд Москвы вечером 6 феврал...</td>\n",
       "      <td>«Фигуранты дела могут давить на свидетелей»</td>\n",
       "      <td>Суд арестовал на два месяца четверых экс-чинов...</td>\n",
       "      <td>2018-02-06 21:21:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.gazeta.ru/business/2013/06/21/5388...</td>\n",
       "      <td>Как повлияло вступление в ВТО на конкурентносп...</td>\n",
       "      <td>«С последних традиционно «отжимают» больше»</td>\n",
       "      <td>Мнения предпринимателей по поводу вступления в...</td>\n",
       "      <td>2013-06-21 17:43:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.gazeta.ru/financial/2011/11/30/385...   \n",
       "1  https://www.gazeta.ru/business/2013/01/24/4939...   \n",
       "2  https://www.gazeta.ru/social/2018/02/06/116393...   \n",
       "3  https://www.gazeta.ru/business/2013/06/21/5388...   \n",
       "\n",
       "                                                text  \\\n",
       "0  «По итогам 2011 года чистый отток может состав...   \n",
       "1  Российское подразделение интернет-корпорации G...   \n",
       "2  Басманный районный суд Москвы вечером 6 феврал...   \n",
       "3  Как повлияло вступление в ВТО на конкурентносп...   \n",
       "\n",
       "                                         title  \\\n",
       "0               Прогноз не успевает за оттоком   \n",
       "1                        Google закончил поиск   \n",
       "2  «Фигуранты дела могут давить на свидетелей»   \n",
       "3  «С последних традиционно «отжимают» больше»   \n",
       "\n",
       "                                             summary                date  \n",
       "0  В 2011 году из России уйдет $80 млрд, считают ... 2011-11-30 18:33:39  \n",
       "1  Юлия Соловьева, экс-директор холдинга «Профмед... 2013-01-24 18:20:09  \n",
       "2  Суд арестовал на два месяца четверых экс-чинов... 2018-02-06 21:21:14  \n",
       "3  Мнения предпринимателей по поводу вступления в... 2013-06-21 17:43:50  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ad268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    morpher = MorphAnalyzer()\n",
    "    sw = set(get_stop_words('ru'))\n",
    "    exclude = set(string.punctuation)\n",
    "  \n",
    "    spls = ''.join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != '']\n",
    "    \n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21591feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question, index, model, index_map):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(300)\n",
    "    norm = 0\n",
    "    \n",
    "    for word in question:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            norm += 1\n",
    "            \n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "        \n",
    "    answers = index.get_nns_by_vector(vector, 3, )\n",
    "    \n",
    "    return [index_map[i] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159895e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_words(text):\n",
    "    lower_text = text.lower()\n",
    "\n",
    "    return lower_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dcad6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [row.split() for row in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3df26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=sentences, vector_size=300, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e298a3af",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.50 GiB for an array with shape (1338489, 300) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m modelFT \u001b[38;5;241m=\u001b[39m \u001b[43mFastText\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py:435\u001b[0m, in \u001b[0;36mFastText.__init__\u001b[1;34m(self, sentences, corpus_file, sg, hs, vector_size, alpha, window, min_count, max_vocab_size, word_ngrams, sample, seed, workers, min_alpha, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, min_n, max_n, sorted_vocab, bucket, trim_rule, batch_words, callbacks, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mvectors_vocab_lockf \u001b[38;5;241m=\u001b[39m ones(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mREAL)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mvectors_ngrams_lockf \u001b[38;5;241m=\u001b[39m ones(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mREAL)\n\u001b[1;32m--> 435\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFastText\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43msentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim_rule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim_rule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_vocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_vocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_final_vocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_final_vocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorted_vocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msorted_vocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnull_word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnull_word\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mns_exponent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mns_exponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhashfxn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhashfxn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnegative\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbow_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcbow_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshrink_windows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_windows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py:429\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[1;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m corpus_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim_rule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim_rule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    431\u001b[0m         corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, total_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_count,\n\u001b[0;32m    432\u001b[0m         total_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_total_words, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs, start_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha,\n\u001b[0;32m    433\u001b[0m         end_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_alpha, compute_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py:497\u001b[0m, in \u001b[0;36mWord2Vec.build_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m report_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_vocab(update\u001b[38;5;241m=\u001b[39mupdate, keep_raw_vocab\u001b[38;5;241m=\u001b[39mkeep_raw_vocab, trim_rule\u001b[38;5;241m=\u001b[39mtrim_rule, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    496\u001b[0m report_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_memory(vocab_size\u001b[38;5;241m=\u001b[39mreport_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_retained_words\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 497\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_vocab\u001b[39m\u001b[38;5;124m\"\u001b[39m, update\u001b[38;5;241m=\u001b[39mupdate, trim_rule\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(trim_rule))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py:853\u001b[0m, in \u001b[0;36mWord2Vec.prepare_weights\u001b[1;34m(self, update)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;66;03m# set initial input/projection and hidden weights\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m update:\n\u001b[1;32m--> 853\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_weights()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py:864\u001b[0m, in \u001b[0;36mWord2Vec.init_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reset all projection weights to an initial (untrained) state, but keep the existing vocabulary.\"\"\"\u001b[39;00m\n\u001b[0;32m    863\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresetting layer weights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 864\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhs:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyn1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwv), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1_size), dtype\u001b[38;5;241m=\u001b[39mREAL)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py:1161\u001b[0m, in \u001b[0;36mFastTextKeyedVectors.resize_vectors\u001b[1;34m(self, seed)\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecalc_char_ngram_buckets()  \u001b[38;5;66;03m# ensure new words have precalc buckets\u001b[39;00m\n\u001b[1;32m-> 1161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjust_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py:1203\u001b[0m, in \u001b[0;36mFastTextKeyedVectors.adjust_vectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors_vocab  \u001b[38;5;66;03m# no ngrams influence\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectors_vocab\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_to_key):\n\u001b[0;32m   1205\u001b[0m     ngram_buckets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuckets_word[i]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.50 GiB for an array with shape (1338489, 300) and data type float32"
     ]
    }
   ],
   "source": [
    "modelFT = FastText(sentences=sentences, vector_size=300, min_count=1, window=5, workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178ca147",
   "metadata": {},
   "source": [
    "Пока не успел доделать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf9a23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
